## üíª Usage

### Starting the Application

1. **Start Airflow** (# üéì Student Performance Dashboard & Ticketing System

A comprehensive data engineering solution for managing student performance data, providing analytics dashboards, and handling feedback through automated sentiment analysis and email notifications.

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Data Pipeline](#data-pipeline)
- [Contributing](#contributing)

## üåü Overview

This system provides a complete end-to-end solution for educational institutions to:
- Manage and analyze student performance data
- Provide students with access to their scores and performance metrics
- Collect and analyze student feedback using AI-powered sentiment analysis
- Automate email notifications based on feedback sentiment
- Transform raw data into normalized relational database structures
- Visualize performance trends and attendance patterns

## ‚ú® Features

### For Students
- **Personal Dashboard**: View individual scores across all subjects
- **Performance Analytics**: See overall performance distributions
- **Anonymous Feedback**: Submit feedback with automatic sentiment analysis
- **Secure Access**: ID-based authentication system

### For Administrators
- **Data Management**: Upload and process student data files
- **Automated Data Cleaning**: Handle missing values, duplicates, and data validation
- **Performance Analytics**: Comprehensive visualizations of student performance
- **Attendance Tracking**: Heatmap visualization of attendance patterns
- **Feedback Monitoring**: Automated email routing based on sentiment

### Technical Features
- **ETL Pipeline**: Automated data extraction, transformation, and loading
- **dbt Transformations**: SQL-based data modeling and transformations
- **Sentiment Analysis**: Multilingual AI model for feedback analysis
- **Workflow Orchestration**: Apache Airflow for task automation
- **Data Visualization**: Interactive charts and heatmaps

## üèóÔ∏è Architecture

```
Raw Data (CSV) 
    ‚Üì
Streamlit Upload Interface
    ‚Üì
Data Cleaning & Processing
    ‚Üì
dbt Seeds & Models
    ‚Üì
MySQL Database (Normalized Schema)
    ‚Üì
Analytics & Visualization
```

**Feedback Pipeline:**
```
Student Feedback
    ‚Üì
Sentiment Analysis (Transformers)
    ‚Üì
Airflow DAG Trigger
    ‚Üì
Conditional Email Routing
```

## üõ†Ô∏è Tech Stack

- **Frontend**: Streamlit
- **Data Processing**: Pandas, NumPy
- **Visualization**: Matplotlib
- **Database**: MySQL
- **Data Transformation**: dbt (Data Build Tool)
- **Workflow Orchestration**: Apache Airflow (Docker)
- **ML/AI**: Hugging Face Transformers (tabularisai/multilingual-sentiment-analysis)
- **Containerization**: Docker & Docker Compose

## üì¶ Prerequisites

- Python 3.8+
- Docker & Docker Compose
- MySQL 8.0+
- dbt CLI
- Git

## üöÄ Installation

### 1. Clone the Repository

```bash
git clone <repository-url>
cd <repository-name>
```

### 2. Install Python Dependencies

```bash
pip install -r src/requirements.txt
```

### 3. Set Up Airflow with Docker

```bash
cd src/Airflow
docker-compose up -d
```

Access Airflow UI at `http://localhost:8080` (default credentials: airflow/airflow)

### 4. Configure dbt

```bash
cd src/Dbt
# Edit profiles.yml with your MySQL credentials
dbt deps
dbt seed
dbt run
```

### 5. Set Up MySQL Database

```sql
-- Run the schema creation script
source src/SQL/Relational\ Schemas
```

## ‚öôÔ∏è Configuration

### Email Configuration (Airflow)

Edit `src/Airflow/docker-compose.yaml`:

```yaml
AIRFLOW__SMTP__SMTP_USER: "your-email@gmail.com"
AIRFLOW__SMTP__SMTP_PASSWORD: "your-app-password"
AIRFLOW__SMTP__SMTP_MAIL_FROM: "your-email@gmail.com"
```

### Email Recipients (DAG)

Edit `src/Airflow/DAG` to configure email routing:

```python
def choose_email(**context):
    sentiment = context["dag_run"].conf.get("sentiment", "Neutral")
    if sentiment in ["Very Negative", "Negative"]:
        return "urgent-support@example.com"
    else:
        return "feedback@example.com"
```

### Database Configuration (dbt)

Update `dbt_folder/profiles.yml`:

```yaml
my_profile:
  target: dev
  outputs:
    dev:
      type: mysql
      host: localhost
      port: 3306
      user: your_username
      password: your_password
      database: student_data
      schema: student_data
```

## üíª Usage

### Starting the Application

1. **Start Airflow** (if not already running):
```bash
cd src/Airflow
docker-compose up -d
```

2. **Launch Streamlit Dashboard**:
```bash
streamlit run src/Streamlit/main.py
```

### Workflow

#### For Administrators:

1. Access the main page and enter admin ID
2. Navigate to "admin" page to upload student data CSV
3. System automatically:
   - Cleans and validates data
   - Runs dbt transformations
   - Updates MySQL database
4. View analytics on "scores" page

#### For Students:

1. Access the main page and enter student ID
2. View personal scores on "scores" page
3. Submit feedback on "feedback" page (minimum 50 characters)
4. System automatically analyzes sentiment and routes email

### Data Upload Format

The system expects CSV files with the following structure:

**Required Columns:**
- `Student_ID`: Unique integer identifier
- `First_Name`: Student's first name (or "Unknown" if missing)
- `Last_Name`: Student's last name (or "Unknown" if missing)
- `Birth_Date`: Date of birth in DD-MM-YYYY format
- `Math`: Math score (0-100)
- `Physics`: Physics score (0-100)
- `Chemistry`: Chemistry score (0-100)
- `Biology`: Biology score (0-100)
- `English`: English score (0-100)
- `History`: History score (0-100)
- `Attendance`: Attendance percentage (0-100)

**Sample Data:**
```csv
Student_ID,First_Name,Last_Name,Math,Physics,Chemistry,Biology,English,History,Attendance,Birth_Date
77,Hassan,Ali,96.0,0.0,34.0,45.0,87.0,52.0,88.0,2004-11-26
1027,Ahmed,Salem,44.0,12.0,12.0,73.0,53.0,0.0,88.0,2001-11-06
44,Hassan,Ali,87.0,47.0,55.0,0.0,53.0,66.0,83.0,2005-03-09
```

**After Processing:**
The system automatically adds:
- `Average_score`: Calculated mean of all subject scores
- `Performance`: Categorized as "High" (‚â•85), "Medium" (‚â•60), or "Low" (<60)

## üìÅ Project Structure

```
src/
‚îú‚îÄ‚îÄ .gitignore                 # Git ignore rules
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ Airflow/
‚îÇ   ‚îú‚îÄ‚îÄ API                    # Sentiment analysis API
‚îÇ   ‚îú‚îÄ‚îÄ DAG                    # Email workflow DAG
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yaml    # Airflow Docker configuration
‚îÇ
‚îú‚îÄ‚îÄ Data Manipulation/
‚îÇ   ‚îú‚îÄ‚îÄ data cleaning          # Data preprocessing scripts
‚îÇ   ‚îî‚îÄ‚îÄ data visualization     # Visualization scripts
‚îÇ
‚îú‚îÄ‚îÄ Dbt/
‚îÇ   ‚îú‚îÄ‚îÄ schema.yaml           # dbt model documentation
‚îÇ   ‚îú‚îÄ‚îÄ students.sql          # Students dimension model
‚îÇ   ‚îú‚îÄ‚îÄ subjects.sql          # Subjects dimension model
‚îÇ   ‚îú‚îÄ‚îÄ scores.sql            # Scores fact table
‚îÇ   ‚îú‚îÄ‚îÄ scores_by_month.sql   # Monthly aggregations
‚îÇ   ‚îî‚îÄ‚îÄ top_performance.sql   # Top performers view
‚îÇ
‚îú‚îÄ‚îÄ SQL/
‚îÇ   ‚îú‚îÄ‚îÄ ER-Diagram.drawio     # Database ER diagram
‚îÇ   ‚îú‚îÄ‚îÄ Relational Schemas    # DDL statements
‚îÇ   ‚îî‚îÄ‚îÄ Split data            # Data migration scripts
‚îÇ
‚îî‚îÄ‚îÄ Streamlit/
    ‚îú‚îÄ‚îÄ main.py               # Login page
    ‚îú‚îÄ‚îÄ admin.py              # Admin control panel
    ‚îú‚îÄ‚îÄ scores.py             # Performance dashboard
    ‚îî‚îÄ‚îÄ feedback.py           # Feedback submission
```

## üîÑ Data Pipeline

### 1. Data Ingestion
- CSV upload through Streamlit interface
- Validation and duplicate removal

### 2. Data Cleaning
- Fill missing values (scores ‚Üí 0, names ‚Üí "Unknown")
- Date standardization
- Calculate average scores and performance categories

### 3. Data Transformation (dbt)
- **Seeds**: Load raw data into MySQL
- **Models**:
  - `students`: Deduplicated student records
  - `subjects`: Reference table for subjects
  - `scores`: Normalized fact table (wide to long format)
  - `scores_by_month`: Monthly performance aggregations
  - `top_performance`: Best performers per subject

### 4. Data Storage
- Normalized MySQL database (3NF)
- Three main tables: Students, Subjects, Scores
- Foreign key relationships maintained

### 5. Analytics & Visualization
- Real-time dashboard updates
- Subject-wise distribution histograms
- Attendance heatmaps

## ü§ñ Sentiment Analysis

The system uses the `tabularisai/multilingual-sentiment-analysis` model to classify feedback into:
- Very Negative
- Negative
- Neutral
- Positive
- Very Positive

Based on sentiment, emails are automatically routed to appropriate recipients.

## üìä Database Schema

### ER Diagram

```
Students (1) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ< (N) Scores (N) >‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ (1) Subjects
   ‚îÇ                      ‚îÇ
   ‚îÇ                      ‚îÇ
Student_ID           Score_ID
First_Name          Student_ID (FK)
Last_Name           Subject_ID (FK)
Birth_Date          Score
```

### Tables

**students**
- `Student_ID` (PK)
- `First_Name`
- `Last_Name`
- `Birth_Date`

**subjects**
- `Subject_ID` (PK)
- `Subject_Name`

**scores**
- `Score_ID` (PK)
- `Student_ID` (FK)
- `Subject_ID` (FK)
- `Score`

## üîê Security Notes

- Store sensitive credentials in `.env` files (not tracked by git)
- Use app passwords for Gmail SMTP
- Implement proper access controls for production deployment
- Feedback is anonymous (no student identification in emails)

## üêõ Troubleshooting

### Airflow Connection Issues
```bash
docker-compose down
docker-compose up -d
# Wait for all services to be healthy
```

### dbt Run Failures
```bash
dbt debug  # Check connection
dbt clean
dbt deps
dbt seed --full-refresh
dbt run --full-refresh
```

### Database Connection Errors
- Verify MySQL is running
- Check credentials in dbt profiles.yml
- Ensure database `student_data` exists

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## üìù License

This project is licensed under the MIT License.

## üë• Authors

- **Data Engineering Team** - Initial work

## üôè Acknowledgments

- Hugging Face for the sentiment analysis model
- Apache Airflow community
- dbt Labs for the transformation framework
- Streamlit for the dashboard framework

---

**Note**: This system is designed for educational purposes. For production deployment, implement additional security measures, scalability considerations, and data privacy compliance.
